{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "notebook_metadata_filter": "-all",
      "text_representation": {
        "extension": ".Rmd",
        "format_name": "rmarkdown"
      }
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PqRwOFPjhlQ"
      },
      "source": [
        "\n",
        "# 1 Introduction\n",
        "\n",
        "Raw tabular datasets can come in many ways. How do you re-organize them for easy manipulation? How do you further prepare the data (filter, select, summarize, etc.) to get them ready for modeling? We will cover these topics in this session. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Tidy Data\n",
        "\n",
        "**Tidy data** is a way to organize tabular data. It provides a guide to structure and store your raw data in a consistent way for easy analysis. A table is tidy if:\n",
        "\n",
        "1. each **variable** forms a **column**.\n",
        "2. each **observation**, or **case**, forms a **row**.\n",
        "3. each **type of observational unit** forms a **table**\n",
        "\n",
        "The tidy data concept is introduced by [Wickham (2014)](http://vita.had.co.nz/papers/tidy-data.html). If you have studied Database design, you will realize that the root of the tidy data idea is Codd's [3rd normal form](https://en.wikipedia.org/wiki/Third_normal_form)."
      ],
      "metadata": {
        "id": "2G7s3MYWQZ4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 \"Messy\" data and why tidy\n",
        "\n",
        "The tidy data definition might be too abstract. Let's start with an example of \"messy\" data.\n",
        "\n",
        "|               | treatmenta  | treatmentb  |\n",
        "|:-------------:|:-----------:|:-----------:|\n",
        "| John Smith    | -           | 2           |\n",
        "| Jane Doe      | 16          | 11          |\n",
        "| Mary Johnson  | 3           | 1           |"
      ],
      "metadata": {
        "id": "KRXS0O_iQfeJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhvnnaXwjhld"
      },
      "source": [
        "# load the tidyverse library\n",
        "# this will load a set of packages\n",
        "library(tidyverse)\n",
        "\n",
        "# create a messy dataset\n",
        "df_messy <- tibble(\n",
        "  name = c(\"John Smith\", \"Jane Doe\", \"Mary Johnson\"),\n",
        "  treatmenta = c(NA, 16, 3),\n",
        "  treatmentb = c(2, 11, 1)\n",
        ")\n",
        "print(df_messy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A0e76cdjhl8"
      },
      "source": [
        "I argue that ideally this dataset should have three variables: `name`, `treatment`, and `result`. The two column headers (`treatmenta` and `treatmentb`) in the current table should be values: treatment `a` or `b`, not variable names (i.e., it violates (1) and (2) in the tidy data definition).\n",
        "\n",
        "The way this dataset is organized makes it hard to retrieve values and analyze them in a *consistent* way. For example, listing all treatment methods would require an operation on column names. On the other hand, listing all subject names is a column-wise operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "eRMyqyrFjhmC"
      },
      "source": [
        "# list all the treatment method\n",
        "print(names(df_messy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ohl1VYEjhmT"
      },
      "source": [
        "# find all the subjects\n",
        "print(df_messy[\"name\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVPrWW8KnzIE"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "What kind of operations (column-wise or row-wise) would you need to perform if I ask the following questions?\n",
        "\n",
        "1. find average treatment result by person\n",
        "2. find average treatment result by treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlagfx4Kjhmj"
      },
      "source": [
        "What if the data looks like this?\n",
        "\n",
        "|               | John Smith  | Jane Doe  | Mary Johnson  |\n",
        "|:-------------:|:-----------:|:---------:|:-------------:|\n",
        "| treatmenta    | -           | 16        | 3             |\n",
        "| treatmentb    | 2           | 11        | 1             |\n",
        "\n",
        "It's just as \"messy\".\n",
        "\n",
        "Imagining you want to build a set of tools/functions to analyze your data, but the raw data you collected are all messy in their own ways. Your tools/functions then need to deal with many different forms of data, which makes the workflow inefficient. That's why we would want to first store/transform raw data in/into a consistent \"tidy\" way.\n",
        "\n",
        "The tidy data way.\n",
        "\n",
        "| name          | treatment | result  |\n",
        "|:-------------:|:---------:|:-------:|\n",
        "| John Smith    | a         | -       |\n",
        "| Jane Doe      | a         | 16      |\n",
        "| Mary Johnson  | a         | 3       |\n",
        "| John Smith    | b         | 2       |\n",
        "| Jane Doe      | b         | 11      |\n",
        "| Mary Johnson  | b         | 1       |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "1fj3U8bgjhmp"
      },
      "source": [
        "# create a tidy dataset\n",
        "df_tidy <- tibble(\n",
        "  name = c(\"John Smith\", \"Jane Doe\", \"Mary Johnson\", \"John Smith\", \"Jane Doe\", \"Mary Johnson\"),\n",
        "  treatment = c(\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"),\n",
        "  result = c(NA, 16, 3, 2, 11, 1)\n",
        ")\n",
        "print(df_tidy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listing all treatment methods and listing all subject names are both column-wise operations."
      ],
      "metadata": {
        "id": "A9R9S3wpMeqS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPr2ERwwjhm3"
      },
      "source": [
        "# list all the treatment method\n",
        "print(unique(df_tidy[\"treatment\"]))\n",
        "\n",
        "# find all the subjects\n",
        "print(unique(df_tidy[\"name\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drPclgHejhnE"
      },
      "source": [
        "## 2.2 From messy to tidy\n",
        "\n",
        "How do we turn a messy dataset into a tidy one? It depends on how messy the dataset is, and in what way. We'll discuss a few examples as a starter.\n",
        "\n",
        "Let's first try to turn the messy data example seen above into a tidy one. There are many ways to do this transformation. Wickham (2014) used `melt()` function in the `reshape2` package. The `reshape2` package was replaced by [`tidyr`](https://tidyr.tidyverse.org/) package around 2015, and `gather()` function was introduced to replace `melt()`. Recently, the `tidyr` team updated `gather()` to [`pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html). Here, we will use the latest `pivot_longer()` approach.\n",
        "\n",
        "`pivot_longer()` \"'lengthens' data, increasing the number of rows and decreasing the number of columns.\" Precisely, it collects a set of column names and places them into a \"names_to\" column. It also collects the cells of those columns and places them into a \"values_to\" column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9K8XWaVjhnI"
      },
      "source": [
        "# tidyr is part of the tidyverse package, which we have already loaded\n",
        "df_tidy_new <- pivot_longer(df_messy, -name, names_to = \"treatment\", values_to = \"result\")\n",
        "print(df_tidy_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7e7NkMZjhnW"
      },
      "source": [
        "Let's take a look at a real world dataset for an exercise. This dataset comes with `tidyr` package. It examines the relationship between income and religion in the US."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "PTqdUXG7jhnc"
      },
      "source": [
        "# religion vs income dataset\n",
        "print(relig_income)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut2Oj2gEjhn4"
      },
      "source": [
        "### Exercise\n",
        "Can you tidy up the pew dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "nz62NXatjhn_"
      },
      "source": [
        "# your code here\n",
        "# uncomment the below line to get started\n",
        "# relig_income_tidy <-"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTSqEFXBjhod"
      },
      "source": [
        "The reverse operation of `pivot_longer()` is `pivot_wider()`. `pivot_wider()` \"widens\" data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "mgJa9Kkbjhoi"
      },
      "source": [
        "relig_income_messy <- pivot_wider(relig_income_tidy, names_from = income, values_from = count)\n",
        "print(relig_income)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYos_jypjhor"
      },
      "source": [
        "`pivot_wider()` can sometimes help tidy up dateset as well. Let's take a look at the `table2` dataset provided by the `tidyr` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SkXhbTFjhou"
      },
      "source": [
        "print(table2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Trjt8-Xjho5"
      },
      "source": [
        "`table2` mixes up the values of `population` and `cases` (TB cases) in the same column `count`. We can use `pivot_wider()` to tidy it up. (Discussion: Is it not tidy already?)\n",
        "\n",
        "### Exercise\n",
        "Use `pivot_wider()` to tidy up the `table2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "XCifnUYfjho8"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbzuQ-3njhpL"
      },
      "source": [
        "## 2.3 Other messy ways\n",
        "\n",
        "According to Wickham (2014), messy datasets have 5 common problems.\n",
        "\n",
        "1. Column headers are values, not variable names.\n",
        "2. Multiple variables are stored in one column.\n",
        "3. Variables are stored in both rows and columns.\n",
        "4. Multiple types of observational units are stored in the same table.\n",
        "5. A single observational unit is stored in multiple tables.\n",
        "\n",
        "We have seen (1) and (2). Let's quickly discuss another example (see slides). I'll leave you to read [(Wickham (2014)](http://vita.had.co.nz/papers/tidy-data.html) to explore the rest. This [site](https://tidyr.tidyverse.org/articles/tidy-data.html) summarizes the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBbX-Ln0jhpX"
      },
      "source": [
        "# 3 Data Transformation\n",
        "\n",
        "R has many tools/packages to manipulate data. We will mainly focus on the `dplyr()` package as it's one of the best. `dplyr()` package is also part of the [`tidyverse`](https://www.tidyverse.org/packages/) eco-system. `tidyverse` consists of a set of packages that deal with data manipulation and other commom data science tasks.\n",
        "\n",
        "Let's first load a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "Uf5BxtENjhpZ"
      },
      "source": [
        "employees <- read_csv(\"https://raw.githubusercontent.com/eijoac/nwdb/master/data/Employees.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "KWcEcNJbjhpi"
      },
      "source": [
        "print(employees)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXETuirmjhpo"
      },
      "source": [
        "print(employees, n = 3, width = Inf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzYEIHrQjhpw"
      },
      "source": [
        "## 3.1 `dplyr` basics\n",
        "\n",
        "* filter observations: `filter()`\n",
        "* select variables: `select()`\n",
        "* reorder rows: `arrange()`\n",
        "* create new variables: `mutate()`\n",
        "* collapse column values to a single summary: `summarise()`\n",
        "\n",
        "The above functions can be used together with `group_by()`, which changes the scope of each function from operating on the whole dataset to operating on each group.\n",
        "\n",
        "Let's try a data manipuation task using the above functions. Find all the sales representatives who were born after 1970-01-01. Display their names and their hiring date. Name should be formatted as \"LastName, FirstName\". Order the output by hiring date (descending)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "05JoZKgvjhp0"
      },
      "source": [
        "# find all the sales representatives who were born after 1970-01-01\n",
        "emp01 <- filter(employees, Title == \"Sales Representative\", BirthDate > 1970-01-01)\n",
        "print(emp01, width = Inf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfvmQkpAjhp6"
      },
      "source": [
        "# create a new variable/column with formatted names as required\n",
        "emp02 <- mutate(emp01, Name = paste(LastName, FirstName, sep = \", \"))\n",
        "\n",
        "# just print the Name variable/column to take a look at the format\n",
        "print(emp02[\"Name\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrOPy9Q2jhqA"
      },
      "source": [
        "In the above code, [`paste()`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/paste.html) is used to concatenate strings. [`glue()`](https://glue.tidyverse.org/) from the glue package might be a bit easier to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "okTxgdsfjhqD"
      },
      "source": [
        "# select the variables/columns (to be displayed)\n",
        "emp03 <- select(emp02, Name, HireDate)\n",
        "print(emp03)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6t8lW7xjhqL"
      },
      "source": [
        "# order by HireDate\n",
        "emp04 <- arrange(emp03, desc(HireDate))\n",
        "print(emp04)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGfP9EXGjhqR"
      },
      "source": [
        "The above steps can be streamlined by using **pipes**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUfqKSQijhqV"
      },
      "source": [
        "# streamline using pipes %>%\n",
        "emp05 <- employees %>%\n",
        "  filter(Title == \"Sales Representative\", BirthDate > 1970-01-01) %>%\n",
        "  mutate(Name = paste(LastName, FirstName, sep = \", \")) %>%\n",
        "  select(Name, HireDate) %>%\n",
        "  arrange(desc(HireDate))\n",
        "\n",
        "print(emp05)\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hqpc_nZjhqs"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Find all employees who are based in USA. Display their names and their birth date. Name should be formatted as \"FirstName LastName\". Order the output by birth date (descending)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "m4V7UeoCjhqv"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJILuDo9jhq-"
      },
      "source": [
        "Let's now count the number of employees by Country. We first need to group data by country using `group_by()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "wxISaKpojhq_"
      },
      "source": [
        "emp_by_country <- group_by(employees, Country)\n",
        "print(emp_by_country)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF2zH6VLjhrG"
      },
      "source": [
        "summarise(emp_by_country, count = n())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV4uwBVhjhrM"
      },
      "source": [
        "In the above code, `n()` is a function for counting. Now, let's use pipe to do the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnpN80s6jhrO"
      },
      "source": [
        "emp_count_by_country <- employees %>%\n",
        "  group_by(Country) %>%\n",
        "  summarise(count = n())\n",
        "print(emp_count_by_country)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG9rRtFyjhrS"
      },
      "source": [
        "Let's load another dataset for your exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "_qODUAwkjhrW"
      },
      "source": [
        "customers <- read_csv(\"https://raw.githubusercontent.com/eijoac/nwdb/master/data/Customers.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCadwvL6jhra"
      },
      "source": [
        "print(customers, width = Inf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiGloKOcjhre"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Find total number of customers per Country and City. Order them by count (descending order)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "CJeGic3-jhri"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC2cL-Sajhrq"
      },
      "source": [
        "Load one more dataset for another exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmAEsOlbjhrt"
      },
      "source": [
        "order_details <- read_csv(\"https://raw.githubusercontent.com/eijoac/nwdb/master/data/OrderDetails.csv\")\n",
        "print(order_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1KhxrYgjhry"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Find all orders with values greater than $12000. Order them by value. Ignore `Discount`. Hint: since each order (identified by `OrderID`) has many items, you need to use `group_by()`. In the `summarise()` function, use `sum()` to sum up item subtotals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "GCdhy1TPjhrz"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "4pXGCRwYjhr8"
      },
      "source": [
        "# answer: method 1\n",
        "order_details %>%\n",
        "  group_by(OrderID) %>%\n",
        "  summarise(TotalOrderValue = sum(UnitPrice * Quantity)) %>%\n",
        "  filter(TotalOrderValue > 12000) %>%\n",
        "  arrange(desc(TotalOrderValue))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPB6Z--yjhsA"
      },
      "source": [
        "# answer: method 2\n",
        "order_details %>%\n",
        "  mutate(SubTotal = UnitPrice * Quantity) %>%\n",
        "  group_by(OrderID) %>%\n",
        "  summarise(TotalOrderValue = sum(SubTotal)) %>%\n",
        "  filter(TotalOrderValue > 12000) %>%\n",
        "  arrange(desc(TotalOrderValue))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CO8oRNejhsH"
      },
      "source": [
        "## 3.2 Join tables\n",
        "\n",
        "Most often, your dataset is organized as a collection of \"tidy\" tables. You need to join them for analysis. The join is based on the relationships between the tables.\n",
        "\n",
        "This is very similar to the concept of a relational database. A database usually consists of many tables and relationships between tables. Let's see an example.\n",
        "\n",
        "![ER](https://raw.githubusercontent.com/eijoac/nwdb/master/er_diagram/NW_ER.png)\n",
        "\n",
        "The above graph represents 8 tables in a database and the relationships between the tables. The graph is called Entity Relationship (ER) diagram. This is a sample database (of a fake company called Northwind) from an old version of MS Access.\n",
        "\n",
        "In the ER diagram, the tiny vertical key icon indicates a column is a primary key. A primary key is a column (or set of columns) whose values uniquely identify every row in a table. For example, `OrderID` is the primary key in the `Orders` table, and `OrderID` and `ProductID` (combined) is the primary key in the `OrderDetails` table.\n",
        "\n",
        "The relationship icon (a line with a horizontal key at one end and an infinite symbol at the other end) indicates a foreign key constraint and a one-to-many relationship. A foreign key is a column (or set of columns) in one table whose values uniquely identify a row of another table or the same table. A foreign key mostly refers to a primary key in another table. A foreign key constraint requires that the constrained column contain only values from the primary key column of the other table. For example `CustomerID` in the `Orders` table is a foreign key that refers to the `CustomerID` primary key in the `Customers` table, and it can only contain values that exist in the `CustomerID` column of the `Customers` table.\n",
        "\n",
        "In addition, it happens that every foreign key constraint in the Northwind DB establishes a one-to-many relationship, i.e. a row from one table can have multiple matching rows in another table. For example, one row from the `Customers` table can match multiple rows in the `Orders` table (via `CustomerID`). This makes sense as one customer can place more than one orders. (Another common relationship a foreign key constraint can establish is the one-to-one relationship.)\n",
        "\n",
        "|logo|meaning|\n",
        "|:------:|:------:|\n",
        "|![key logo](https://raw.githubusercontent.com/eijoac/nwdb/master/er_diagram/key_vertical.png \"key logo\")|primary key|\n",
        "|![foreign key constraint](https://raw.githubusercontent.com/eijoac/nwdb/master/er_diagram/relationship.png \"foreign key constraint\")|one-to-many foreign key constraint|\n",
        "\n",
        "Why do we need foreign key constraints? (Discussion)\n",
        "\n",
        "In a database, the relationships/constraints will be stored and enforced by the DB management system. Here we will just load the data as raw files to dataframes/tibbles so there is no mechanism to enforce the relationships.\n",
        "\n",
        "Let's learn how to join datasets.\n",
        "\n",
        "* inner join\n",
        "* left / right join, and left / right join with exclusion\n",
        "* full join, full outer join\n",
        "\n",
        "Let's do some experiments using two small datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "h5t6EHOJjhsK"
      },
      "source": [
        "t1 <- tribble(\n",
        "  ~pk, ~t1c1,\n",
        "     1, \"a\",\n",
        "     2, \"b\"\n",
        ")\n",
        "t2 <- tribble(\n",
        "  ~fk, ~t2c1,\n",
        "     1, \"c\",\n",
        "     1, \"d\",\n",
        "     3, \"e\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "gvtYAu2cjhsR"
      },
      "source": [
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "EL26HgJEjhsY"
      },
      "source": [
        "print(t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WRRqgiujhse"
      },
      "source": [
        "# playground for join exercises\n",
        "\n",
        "# inner join\n",
        "t1 %>% inner_join(t2, by = c(\"pk\" = \"fk\"))\n",
        "\n",
        "# left join\n",
        "# t1 %>% left_join(t2, by = c(\"pk\" = \"fk\"))\n",
        "\n",
        "# left join with exclusion\n",
        "# t1 %>% left_join(t2, by = c(\"pk\" = \"fk\")) %>% filter(is.na(t2c1))\n",
        "\n",
        "# right join\n",
        "# t1 %>% right_join(t2, by = c(\"pk\" = \"fk\"))\n",
        "\n",
        "# right join with exclusion\n",
        "# t1 %>% right_join(t2, by = c(\"pk\" = \"fk\")) %>% filter(is.na(t1c1))\n",
        "\n",
        "# full join\n",
        "# t1 %>% full_join(t2, by = c(\"pk\" = \"fk\"))\n",
        "\n",
        "# full outer join\n",
        "# t1 %>% full_join(t2, by = c(\"pk\" = \"fk\")) %>% filter(is.na(t1c1) | is.na(t2c1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lAA7sIvjhsi"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "ex1. What is `semi_join()` and `anti_join` in `dplyr()`? Is `semi_join()` the same as `inner_join`? Is `anti_join()` the same as left join with exclusion we discussed above?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "gQZPn3ppjhsk"
      },
      "source": [
        "# test it out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwra3XT4jhsr"
      },
      "source": [
        "# inner join t1 with t2\n",
        "t1 %>%\n",
        "  inner_join(t2, by = c(\"pk\" = \"fk\"))\n",
        "\n",
        "# semi-join t1 with t2\n",
        "t1 %>%\n",
        "  semi_join(t2, by = c(\"pk\" = \"fk\"))\n",
        "\n",
        "# left join t1 with t2 and with exclusion\n",
        "t1 %>%\n",
        "  left_join(t2, by = c(\"pk\" = \"fk\")) %>%\n",
        "  filter(is.na(t2c1))\n",
        "\n",
        "# anti-join t1 with t2\n",
        "t1 %>%\n",
        "  anti_join(t2, by = c(\"pk\" = \"fk\"))\n",
        "\n",
        "# make a new table\n",
        "t3 <- tribble(\n",
        "  ~pk, ~t1c1,\n",
        "     1, \"a\",\n",
        "     2, \"b\",\n",
        "     2, \"b\"\n",
        ")\n",
        "\n",
        "# left join t3 with t2 and with exclusion\n",
        "t3 %>%\n",
        "  left_join(t2, by = c(\"pk\" = \"fk\")) %>%\n",
        "  filter(is.na(t2c1))\n",
        "\n",
        "# anti-join t3 with t2\n",
        "t3 %>%\n",
        "  anti_join(t2, by = c(\"pk\" = \"fk\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVwYowL4jhtC"
      },
      "source": [
        "Let's load the rest of Northwind dataset and do something a bit more interesting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp0tYOBwjhtE"
      },
      "source": [
        "orders <- read_csv(\"https://raw.githubusercontent.com/eijoac/nwdb/master/data/Orders.csv\")\n",
        "shippers <- read_csv(\"https://raw.githubusercontent.com/eijoac/nwdb/master/data/Shippers.csv\")\n",
        "suppliers <- read_csv(\"https://raw.githubusercontent.com/eijoac/nwdb/master/data/Suppliers.csv\")\n",
        "products <- read_csv(\"https://raw.githubusercontent.com/eijoac/nwdb/master/data/Products.csv\")\n",
        "categories <- read_csv(\"https://raw.githubusercontent.com/eijoac/nwdb/master/data/Categories.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCz4nZSqjhtI"
      },
      "source": [
        "ex2. Display all products and their associated suppliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "gqTbAKeRjhtM"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckxgjHZOjhtQ"
      },
      "source": [
        "# answer\n",
        "# products %>%\n",
        "#   inner_join(suppliers, by = 'SupplierID')\n",
        "\n",
        "products %>%\n",
        "  left_join(suppliers, by = 'SupplierID')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEmoSYjzjhtU"
      },
      "source": [
        "ex3. Find all orders with values great than $12000 and are placed in 2016."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZVSMfvojhtU"
      },
      "source": [
        "# let's do it together\n",
        "library(lubridate)\n",
        "orders %>%\n",
        "  filter(year(OrderDate) == 2016) %>%\n",
        "  inner_join(order_details, by = \"OrderID\") %>%\n",
        "  group_by(OrderID) %>%\n",
        "  summarise(TotalOrderValue = sum(UnitPrice * Quantity)) %>%\n",
        "  filter(TotalOrderValue > 12000) %>%\n",
        "  arrange(desc(TotalOrderValue))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WhPqaH6jhtb"
      },
      "source": [
        "ex4. Find customers that never placed an order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "4dwKdZ1kjhtd"
      },
      "source": [
        "# let's do it together\n",
        "# method 1\n",
        "customers %>%\n",
        "  left_join(orders, by = \"CustomerID\") %>%\n",
        "  filter(is.na(OrderID))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4zHtnTAjhtg"
      },
      "source": [
        "# let's do it together\n",
        "# method 2 - using anti_join\n",
        "customers %>%\n",
        "  anti_join(orders, by = \"CustomerID\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4I0k2sSjhtl"
      },
      "source": [
        "ex5. Find customers who never placed an order from Margaret Peacock (EmployeeID 4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "wkTV9ihUjhts"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "T1qTVdtDjhtw"
      },
      "source": [
        "# answer: method 1\n",
        "orders_4 <- orders %>%\n",
        "  filter(EmployeeID == 4)\n",
        "\n",
        "customers %>%\n",
        "  anti_join(orders_4, by = \"CustomerID\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "aXJGWderjht0"
      },
      "source": [
        "customers %>%\n",
        "  left_join(orders_4, by = \"CustomerID\") %>%\n",
        "  filter(is.na(OrderID))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjax9aGSjht3"
      },
      "source": [
        "# answer: method 2\n",
        "orders %>%\n",
        "  filter(EmployeeID == 4) %>%\n",
        "  right_join(customers, by = \"CustomerID\") %>%\n",
        "  filter(is.na(OrderID))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMTlGvJIjht7"
      },
      "source": [
        "ex6. Find all orders and their shippers with OrderID less than 10255. Display `OrderID`, `OrderDate` (date only), and Shipper `CompanyName`. Hint: use `as.Date()` to convert `OrderDate` (Datetime type) to Date."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "S6g_IFp-jht9"
      },
      "source": [
        "# let's do it together\n",
        "orders %>%\n",
        "  inner_join(shippers, by = c(\"ShipVia\" = \"ShipperID\")) %>%\n",
        "  filter(OrderID < 10255) %>%\n",
        "  mutate(OrderDate = as.Date(OrderDate)) %>%\n",
        "  select(OrderID, OrderDate, CompanyName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tglf_cNkjhuA"
      },
      "source": [
        "# References\n",
        "\n",
        "1. Tidyverse package [site](https://www.tidyverse.org/).\n",
        "2. Tidy data paper intro and code [site](https://tidyr.tidyverse.org/articles/tidy-data.html).\n",
        "3. Hadley Wickham's Tidy data [paper](https://www.jstatsoft.org/article/view/v059i10).\n",
        "4. Garrett Grolemund's Data Tidying [tutorial](http://garrettgman.github.io/tidying/).\n",
        "5. [Data Wrangle](https://r4ds.had.co.nz/wrangle-intro.html) in [R for Data Science](https://r4ds.had.co.nz/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "FVWIU3y3jhuB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}